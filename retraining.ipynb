{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img('data/0Xf5QSSF2b.jpg')  # this is a PIL image\n",
    "x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "# the .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the `preview/` directory\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir='view', save_prefix='example', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(3, 150, 150), data_format=\"channels_first\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), data_format=\"channels_first\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into dataframe with 'path' and 'target' columns\n",
    "import pandas as pd\n",
    "train_label_df = pd.read_csv('data.csv', delimiter=' ', header=1, names=[\"uid\"])\n",
    "train_label_df[\"path\"] = train_label_df['uid'].apply(lambda x : x.split(',')[-1])\n",
    "train_label_df[\"target\"] = train_label_df['uid'].apply(lambda x : int(x.split(',')[1])/int(x.split(',')[2]))\n",
    "train_label_df =train_label_df.drop(['uid'], axis=1)\n",
    "\n",
    "train_label_df2 = pd.read_csv('data_temp.csv', delimiter=' ', header=1, names=[\"uid\"])\n",
    "train_label_df2[\"path\"] = train_label_df2['uid'].apply(lambda x : \"./data/\" + x.split(',')[0] + \".jpg\")\n",
    "train_label_df2[\"target\"] = train_label_df2['uid'].apply(lambda x : int(x.split(',')[1])/int(x.split(',')[3]))\n",
    "train_label_df2 =train_label_df2.drop(['uid'], axis=1)\n",
    "#uid,likes,comments,followers\n",
    "#B-A-bW9l1Gm,601,43,6715"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/B9dZzI1n-EV.jpg</td>\n",
       "      <td>0.112025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./data/B9cQMfVnkMe.jpg</td>\n",
       "      <td>0.638448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./data/B9a0IQWnY9M.jpg</td>\n",
       "      <td>0.053981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./data/B9NnTUrHoNX.jpg</td>\n",
       "      <td>0.143885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./data/B9XuP83gx_j.jpg</td>\n",
       "      <td>0.030143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>./data/B9eu_7jHaaN.jpg</td>\n",
       "      <td>0.030105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>./data/B9eyOJ3gMBl.jpg</td>\n",
       "      <td>0.020260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>./data/B9erbIMHAhH.jpg</td>\n",
       "      <td>0.195320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>./data/B9e2JraBbFd.jpg</td>\n",
       "      <td>0.026655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>./data/B9fG2fHhRrZ.jpg</td>\n",
       "      <td>0.015340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>619 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       path    target\n",
       "0    ./data/B9dZzI1n-EV.jpg  0.112025\n",
       "1    ./data/B9cQMfVnkMe.jpg  0.638448\n",
       "2    ./data/B9a0IQWnY9M.jpg  0.053981\n",
       "3    ./data/B9NnTUrHoNX.jpg  0.143885\n",
       "4    ./data/B9XuP83gx_j.jpg  0.030143\n",
       "..                      ...       ...\n",
       "614  ./data/B9eu_7jHaaN.jpg  0.030105\n",
       "615  ./data/B9eyOJ3gMBl.jpg  0.020260\n",
       "616  ./data/B9erbIMHAhH.jpg  0.195320\n",
       "617  ./data/B9e2JraBbFd.jpg  0.026655\n",
       "618  ./data/B9fG2fHhRrZ.jpg  0.015340\n",
       "\n",
       "[619 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/B-A4q2_HbZM.jpg</td>\n",
       "      <td>0.021855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./data/B-A67qNleZJ.jpg</td>\n",
       "      <td>0.155491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./data/B-AaOGUhKbv.jpg</td>\n",
       "      <td>0.040524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./data/B-ACyP7JemN.jpg</td>\n",
       "      <td>0.027340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./data/B-Ar4y3hXX2.jpg</td>\n",
       "      <td>0.067915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>./data/B9M_-rNg0Er.jpg</td>\n",
       "      <td>0.289023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>./data/B9WejSrBIsL.jpg</td>\n",
       "      <td>0.917219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>./data/B9wPREWhq0l.jpg</td>\n",
       "      <td>0.128363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>./data/B9Y_fqoHwUn.jpg</td>\n",
       "      <td>0.286299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>./data/B9Y2fYmne_p.jpg</td>\n",
       "      <td>0.022442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>815 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       path    target\n",
       "0    ./data/B-A4q2_HbZM.jpg  0.021855\n",
       "1    ./data/B-A67qNleZJ.jpg  0.155491\n",
       "2    ./data/B-AaOGUhKbv.jpg  0.040524\n",
       "3    ./data/B-ACyP7JemN.jpg  0.027340\n",
       "4    ./data/B-Ar4y3hXX2.jpg  0.067915\n",
       "..                      ...       ...\n",
       "810  ./data/B9M_-rNg0Er.jpg  0.289023\n",
       "811  ./data/B9WejSrBIsL.jpg  0.917219\n",
       "812  ./data/B9wPREWhq0l.jpg  0.128363\n",
       "813  ./data/B9Y_fqoHwUn.jpg  0.286299\n",
       "814  ./data/B9Y2fYmne_p.jpg  0.022442\n",
       "\n",
       "[815 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_label_df, train_label_df2], axis=0).reset_index().drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/B9dZzI1n-EV.jpg</td>\n",
       "      <td>0.112025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./data/B9cQMfVnkMe.jpg</td>\n",
       "      <td>0.638448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./data/B9a0IQWnY9M.jpg</td>\n",
       "      <td>0.053981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./data/B9NnTUrHoNX.jpg</td>\n",
       "      <td>0.143885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./data/B9XuP83gx_j.jpg</td>\n",
       "      <td>0.030143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>./data/B9M_-rNg0Er.jpg</td>\n",
       "      <td>0.289023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>./data/B9WejSrBIsL.jpg</td>\n",
       "      <td>0.917219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>./data/B9wPREWhq0l.jpg</td>\n",
       "      <td>0.128363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>./data/B9Y_fqoHwUn.jpg</td>\n",
       "      <td>0.286299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>./data/B9Y2fYmne_p.jpg</td>\n",
       "      <td>0.022442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1434 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        path    target\n",
       "0     ./data/B9dZzI1n-EV.jpg  0.112025\n",
       "1     ./data/B9cQMfVnkMe.jpg  0.638448\n",
       "2     ./data/B9a0IQWnY9M.jpg  0.053981\n",
       "3     ./data/B9NnTUrHoNX.jpg  0.143885\n",
       "4     ./data/B9XuP83gx_j.jpg  0.030143\n",
       "...                      ...       ...\n",
       "1429  ./data/B9M_-rNg0Er.jpg  0.289023\n",
       "1430  ./data/B9WejSrBIsL.jpg  0.917219\n",
       "1431  ./data/B9wPREWhq0l.jpg  0.128363\n",
       "1432  ./data/B9Y_fqoHwUn.jpg  0.286299\n",
       "1433  ./data/B9Y2fYmne_p.jpg  0.022442\n",
       "\n",
       "[1434 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " '0Xf5QSSF2b.jpg',\n",
       " '0Xh5lwSF4_.jpg',\n",
       " '0XhcghSF4Y.jpg',\n",
       " 'B-A-bW9l1Gm.jpg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "onlyfiles = [f for f in listdir('data') if isfile(join('data', f))]\n",
    "onlyfiles[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = train_df\n",
    "for i in train_df['path']:\n",
    "    if i.split(\"/\")[-1] not in onlyfiles:\n",
    "        print(train_df.index[train_df['path'] == i].tolist())\n",
    "# All are found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\weustis\\miniconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 1434 invalid image filename(s) in x_col=\"path\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "    rotation_range=1,\n",
    "    \n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        x_col = 'path',\n",
    "        y_col = 'target',\n",
    "        directory='data',\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='other')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "#validation_generator = test_datagen.flow_from_directory(\n",
    "#        'data/validation',\n",
    "#        target_size=(150, 150),\n",
    "#        batch_size=batch_size,\n",
    "#        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available()\n",
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\weustis\\miniconda3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\users\\weustis\\miniconda3\\lib\\threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\weustis\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\data_utils.py\", line 748, in _run\n",
      "    with closing(self.executor_fn(_SHARED_SEQUENCES)) as executor:\n",
      "  File \"c:\\users\\weustis\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\data_utils.py\", line 727, in pool_fn\n",
      "    initargs=(seqs, None, get_worker_id_queue()))\n",
      "  File \"c:\\users\\weustis\\miniconda3\\lib\\multiprocessing\\context.py\", line 119, in Pool\n",
      "    context=self.get_context())\n",
      "  File \"c:\\users\\weustis\\miniconda3\\lib\\multiprocessing\\pool.py\", line 174, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"c:\\users\\weustis\\miniconda3\\lib\\multiprocessing\\pool.py\", line 239, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"c:\\users\\weustis\\miniconda3\\lib\\multiprocessing\\process.py\", line 105, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"c:\\users\\weustis\\miniconda3\\lib\\multiprocessing\\context.py\", line 322, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"c:\\users\\weustis\\miniconda3\\lib\\multiprocessing\\popen_spawn_win32.py\", line 65, in __init__\n",
      "    reduction.dump(process_obj, to_child)\n",
      "  File \"c:\\users\\weustis\\miniconda3\\lib\\multiprocessing\\reduction.py\", line 60, in dump\n",
      "    ForkingPickler(file, protocol).dump(obj)\n",
      "TypeError: can't pickle _thread.lock objects\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=800 // batch_size,\n",
    "        epochs=50,\n",
    "        #validation_data=validation_generator,\n",
    "        #validation_steps=800 // batch_size)\n",
    "        verbose = 2,\n",
    "        max_queue_size = 20,\n",
    "        use_multiprocessing=False,\n",
    "        shuffle=True\n",
    ")\n",
    "model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
